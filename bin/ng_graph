#!/usr/bin/env python3.6
# ng_graph.py
"""Script for generating graphs from ng_trajectory files."""
######################
# Imports & Globals
######################

import sys
import os
import argparse

# It is possible to do it using the library, but we skip on this now
# to actually do not require all dependencies + speed up the process.
# import ng_trajectory
import json

import statistics

import matplotlib.colors
import matplotlib.pyplot
import matplotlib.ticker
import matplotlib.markers

# Darkening and lightening the colors
import colorsys

# Progress bar
import tqdm

from typing import List, Tuple, Dict, TextIO

# Parallel computing of steps
from concurrent import futures


# Custom types
class listA(list):
    """Advanced list subclass that is more suited for our use-case."""

    def get(self, index):
        """Return the element at index if possible, or last element."""
        return (
            self.__getitem__(index) if index < self.__len__()
            else self.__getitem__(-1)
        )


# Decorators
def parallel(real_function):
    """Decorate to support parallelization of given function.

    We expect that first parameter of the function is iterable.

    When `args.jobs > 0` the ProcessPoolExecutor is created.
    Otherwise, function is run sequentially.

    Note: Because of pickle, we have to actually decorate different
    function then the one that is used for ProcessPoolExecutor.

    Therefore, the expected usage is as follows:
    ```
    def _real_function():
        # Do something.
        pass

    @parallel(_real_function)
    def called_function(*args, **kwargs):
        # This can be empty, as it is not used.
        pass

    # Run it as
    called_function()
    ```

    Source:
    https://stackoverflow.com/questions/642762/is-it-possible-to-replace-a-python-function-method-decorator-at-runtime
    https://stackoverflow.com/questions/63473520/cannot-use-processpoolexecutor-if-in-a-decorator
    """
    def decorate(f):
        def cond_parallel(*a, **kwargs):
            global args

            def run_parallely(*a, **kwargs):
                with futures.ProcessPoolExecutor(
                        max_workers = args.jobs
                ) as executor:
                    for x in executor.map(real_function, a[0]):
                        yield x

            def run_sequentially(*a, **kwargs):
                for x in a[0]:
                    yield real_function(x)

            return (
                run_parallely(*a, **kwargs) if args.jobs > 0
                else run_sequentially(*a, **kwargs)
            )

        return cond_parallel
    return decorate


# Global variables
PARSER = argparse.ArgumentParser(
    prog = "ng_graph",
    formatter_class=argparse.RawDescriptionHelpFormatter,
    description = """
Script for generating graphs from ng_trajectory files.

When using a '.json' configuration file we expect that the logs
are in the same location.
    """,
)


# Custom actions
class store_selection(argparse.Action):
    """Custom action to handle values selection (e.g., pages from a document).

    The behaviour is controlled by parameter 'action_style',
    defaults to 'numeric'.

    - numeric:
    All numbers are delimited by ','. May contain ranges, defined by '-'.

    - numeric_mixed:
    Same as numeric, but also allows strings.

    Example:
    > 1,3,5-9,4-2,2
    1 3 5 6 7 8 9 4 3 2 2

    Source:
    https://stackoverflow.com/questions/8632354/python-argparse-custom-actions-with-additional-arguments-passed
    """

    def __init__(
            self,
            option_strings,
            action_style = "numeric",
            *args,
            **kwargs):
        """Initialize the custom selector."""
        super(store_selection, self).__init__(
            option_strings = option_strings,
            *args,
            **kwargs
        )
        self.action_style = action_style


    def __call__(self, parser, namespace, values, option_string = None):
        """Convert values selection to a list of values."""
        _values = listA()

        for num in values.split(","):
            try:
                if "-" in num:
                    _n1 = int(num[:num.index("-")])
                    _n2 = int(num[num.index("-") + 1:])

                    if _n2 > _n1:
                        _values += list(range(_n1, _n2 + 1))
                    else:
                        _values += list(range(_n2, _n1 - 1, -1))
                else:
                    if self.action_style == "numeric_mixed":
                        _values.append(int(num) if num.isdecimal() else num)
                    else:
                        _values.append(int(num))
            except Exception:
                raise parser.error(
                    "argument %s: unable to parse '%s'" % (option_string, num)
                )

        setattr(namespace, self.dest, _values)


# Custom types
class ReadableFile(object):
    """Object the check whether argument is a file that exists and is readable.

    Source:
    https://baoshangu.medium.com/python-argparse-custom-action-and-custom-type-8c8fa1e8ccb8
    """

    def __init__(self):
        """Initialize the custom type."""
        super(ReadableFile, self).__init__()

    def __call__(self, filename):
        """Check whether the file is readable.

        Arguments:
        filename -- name of the file to check, str

        Raises:
        argparse.ArgumentTypeError when not readable
        """
        if not os.access(filename, os.R_OK):
            raise argparse.ArgumentTypeError(
                (
                    "permission denied '%s'"
                    if os.access(filename, os.F_OK)
                    else "no such file '%s'"
                ) % filename
            )

        return filename


# Argument groups
GRAPH_PARSER = PARSER.add_argument_group(
    "graph arguments",
    "Arguments controlling displayed/saved graph."
)
JSON_MODE_PARSER = PARSER.add_argument_group(
    "json optional arguments",
    "Arguments used only when working with jsons (without '-l')."
)
LOG_MODE_PARSER = PARSER.add_argument_group(
    "log optional arguments",
    "Arguments used only when working with logs (with '-l')."
)

# Arguments
PARSER.add_argument(
    "input_file",

    nargs = "+",
    help = "Path to the ng_trajectory file.",
    type = ReadableFile(),
)

PARSER.add_argument(
    "-v",

    dest = "verbose",
    help = "Give more output.",
    action = "store_true",
)

PARSER.add_argument(
    "-l",

    dest = "logfile",
    help = "Treat the input file as a log file.",
    action = "store_true",
)

PARSER.add_argument(
    "-s",

    dest = "save",
    help = "Hide the graph and save it into %%s.pdf and %%s.png.",
    action = "store_true",
)

PARSER.add_argument(
    "-Q",

    dest = "quantiles",
    help = "Quantiles / Percentiles to compute and show.",
    action = "append",
    default = [],
    type = int,
)

PARSER.add_argument(
    "-O",

    dest = "outfile",
    help = "Set the output file name to be used instead of %%s.",
    default = None,
    type = str,
)

PARSER.add_argument(
    "-j",

    dest = "jobs",
    help = (
        "Set the number of threads used for log processing. "
        "(Defaults to 0, which omits the ProcessPoolExecutor entirely.)"
    ),
    default = 0,
    type = int,
)

GRAPH_PARSER.add_argument(
    "--dpi",

    dest = "dpi",
    help = "DPI value used for exporting the figures.",
    default = 300,
    type = int,
)

GRAPH_PARSER.add_argument(
    "--width",

    dest = "width",
    help = (
        "Width of the figure in inches. "
        "Defaults to 'matplotlib.rcParams[figure.figsize]'."
    ),
    default = matplotlib.rcParams.get("figure.figsize", [6.4, 4.8])[0],
    type = float,
)

GRAPH_PARSER.add_argument(
    "--height",

    dest = "height",
    help = (
        "Height of the figure in inches. "
        "Defaults to 'matplotlib.rcParams[figure.figsize]'."
    ),
    default = matplotlib.rcParams.get("figure.figsize", [6.4, 4.8])[1],
    type = float,
)

GRAPH_PARSER.add_argument(
    "--tight",

    dest = "tight",
    help = "Adjusts the padding around the figure.",
    action = "store_true",
)

GRAPH_PARSER.add_argument(
    "--hide-min",

    dest = "show_min",
    help = "Hide minimum value cap in the figure.",
    action = "store_false",
)

GRAPH_PARSER.add_argument(
    "--hide-max",

    dest = "show_max",
    help = "Hide maximum value cap in the figure.",
    action = "store_false",
)

GRAPH_PARSER.add_argument(
    "--hide-avg",

    dest = "show_avg",
    help = "Hide average value marker in the figure.",
    action = "store_false",
)

GRAPH_PARSER.add_argument(
    "--hide-bar",

    dest = "show_bar",
    help = "Hide error bar in the figure.",
    action = "store_false",
)

PARSER.add_argument(
    "--merged-min",

    dest = "merged_min",
    help = (
        "Merge the minimum of loops and draw a graph of that. "
        "(IROS-like graph.)\nWhen used with '-l' merge the logs together."
    ),
    action = "store_true",
)

GRAPH_PARSER.add_argument(
    "--ymin",

    dest = "ymin",
    help = "Minimum value on y-axis to be shown in the figure.",
    type = float,
)

GRAPH_PARSER.add_argument(
    "--ymax",

    dest = "ymax",
    help = "Maximum value on y-axis to be shown in the figure.",
    type = float,
)

GRAPH_PARSER.add_argument(
    "--marker",

    choices = list(matplotlib.markers.MarkerStyle.markers.keys()),
    dest = "marker",
    help = "Marker style used in the figure. Same as 'matplotlib.markers'.",
    default = "_",
    type = str,
)

GRAPH_PARSER.add_argument(
    "--marker-avg",

    choices = list(matplotlib.markers.MarkerStyle.markers.keys()),
    dest = "marker_avg",
    help = (
        "Marker style used for averages in the figure. "
        "Same as 'matplotlib.markers'."
    ),
    type = str,
    action = "append",
    default = listA("o")
)

GRAPH_PARSER.add_argument(
    "--markersize",

    dest = "markersize",
    help = "Marker size used in the figure.",
    default = 10.0,
    type = float,
)

GRAPH_PARSER.add_argument(
    "--show-legend",

    dest = "show_legend",
    help = "Show the legend in the figure.",
    action = "store_true",
)

GRAPH_PARSER.add_argument(
    "--loc-legend",

    choices = list(matplotlib.offsetbox.AnchoredOffsetbox.codes.keys()),
    dest = "loc_legend",
    help = "Location of the legend. Same as 'loc' for 'matplotlib.legend'.",
    type = str,
)

GRAPH_PARSER.add_argument(
    "--label",

    dest = "label",
    help = (
        "Label of dataset to be displayed in the legend. "
        "Overwrites value of '_label' inside of the configuration. "
        "(Use multiple times to set labels for other configuration files.)"
    ),
    action = "append",
    type = str,
)

GRAPH_PARSER.add_argument(
    "--title",

    dest = "title",
    help = "Title of the figure. (Hidden when not set.)",
    default = "",
    type = str,
)

PARSER.add_argument(
    "--step",

    dest = "step",
    help = "Zero-based index of cascade step to used.",
    default = 0,
    type = int,
)

LOG_MODE_PARSER.add_argument(
    "-p",

    dest = "plot_friendly",
    help = "Output information in plot friendly format.",
    action = "store_true",
)

PARSER.add_argument(
    "-r",

    dest = "recursive_find",
    help = "Look for the log files in subfolders as well.",
    action = "store_true",
)

LOG_MODE_PARSER.add_argument(
    "-g",

    dest = "show_graph",
    help = "Show the graph of the processed data.",
    action = "store_true",
)

LOG_MODE_PARSER.add_argument(
    "--segments",

    dest = "segments",
    help = "Numbers of segments to be used for x-axis, e.g., 1,2,1,6-9,3.",
    action = store_selection,
    default = [],
)

JSON_MODE_PARSER.add_argument(
    "--variates",

    dest = "variates",
    help = (
        "Values of variates to show in the graph, delimited by commas. "
        "Supports ranges '-'."
    ),
    action = store_selection,
    action_style = "numeric_mixed",
    default = [],
)

JSON_MODE_PARSER.add_argument(
    "--datasets",

    dest = "datasets",
    help = (
        "Zero-based indices indicating to which dataset the configuration "
        "file belongs. Supports ranges '-'."
    ),
    action = store_selection,
    default = [],
)

LOG_MODE_PARSER.add_argument(
    "--no-header",

    dest = "no_header",
    help = "Do not print out the header when using '-p'.",
    action = "store_true",
)


######################
# Graph class
######################

class Graph(object):
    """Object for handling graphs plotting."""

    def __init__(
            self,
            xlabel = "",
            ylabel = "",
            grid = True,
            show_min: bool = True,
            show_max: bool = True,
            show_avg: bool = True,
            show_bar: bool = True,
            marker: str = "_",
            markersize: float = 10.0,
            width: float = 6.4,
            height: float = 4.8):
        """Initialize Graph object."""
        super(Graph, self).__init__()

        self.__figure = matplotlib.pyplot.figure(figsize = (width, height))
        self.__axes = self.__figure.add_subplot(111)

        if xlabel != "":
            self.__axes.set_xlabel(xlabel)

        if ylabel != "":
            self.__axes.set_ylabel(ylabel)

        if grid:
            self.__axes.grid(color = "lightgray", dashes = (5, 5))

        self.__show_min = show_min
        self.__show_max = show_max
        self.__show_avg = show_avg
        self.__show_bar = show_bar

        self.__marker = marker
        self.__markersize = markersize

        self.__legend_handles = []

        # Category10 Tableau colors
        # https://matplotlib.org/3.5.0/users/prev_whats_new/dflt_style_changes.html
        self.__colors = [
            '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',
            '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'
        ]

        # Changing the brightness
        # https://stackoverflow.com/questions/37765197/darken-or-lighten-a-color-in-matplotlib
        self.__colors_lighter = [
            scale_lightness(
                matplotlib.colors.ColorConverter.to_rgb(_color),
                1.3
            ) for _color in self.__colors
        ]

        self.__colors_lighter2 = [
            scale_lightness(
                matplotlib.colors.ColorConverter.to_rgb(_color),
                2.0
            ) for _color in self.__colors
        ]


    def lighten_color(self, dataset: int = 0, scale: float = 1.0):
        """Increase lightness of a dataset color."""
        return scale_lightness(
            matplotlib.colors.ColorConverter.to_rgb(self.__colors[dataset]),
            scale
        )


    def plot_log(self, log, variate = 0, dataset = 0, marker = "o"):
        """Plot a Log into this Graph."""
        # Skip when all failed
        if log.mean is None:
            return

        dataset = dataset % len(self.__colors)

        if self.__show_avg:
            matplotlib.pyplot.scatter(
                variate,
                log.mean,
                color = self.__colors[dataset],
                s = 50,
                marker = marker,
                **{"facecolors": "none"} if log.failed else {}
            )

        for _q in log.quantile_show_list:
            if _q < 50:
                if self.__show_bar:
                    _, caplines, _ = matplotlib.pyplot.errorbar(
                        [variate],
                        [log.mean],
                        yerr = [log.mean - log.quantile(_q)],
                        figure = self.__figure,
                        color = self.lighten_color(dataset, 1.0 + (_q / 50)),
                        capsize = 0,
                        uplims = True
                    )

                    caplines[0].set_marker(self.__marker)
                    caplines[0].set_markersize(self.__markersize)
                else:
                    matplotlib.pyplot.plot(
                        variate,
                        log.quantile(_q),
                        figure = self.__figure,
                        color = self.lighten_color(dataset, 1.0 + (_q / 50)),
                        marker = self.__marker,
                        markersize = self.__markersize
                    )
            elif _q > 50:
                if self.__show_bar:
                    # Show only one limit and change carets to caps
                    # https://stackoverflow.com/questions/45752981/removing-the-bottom-error-caps-only-on-matplotlib

                    _, caplines, _ = matplotlib.pyplot.errorbar(
                        [variate],
                        [log.mean],
                        yerr = [log.quantile(_q) - log.mean],
                        figure = self.__figure,
                        color = self.lighten_color(
                            dataset, 2.0 - ((_q - 50) / 50)
                        ),
                        capsize = 0,
                        lolims = True
                    )

                    caplines[0].set_marker(self.__marker)
                    caplines[0].set_markersize(self.__markersize)
                else:
                    matplotlib.pyplot.plot(
                        variate,
                        log.quantile(_q),
                        figure = self.__figure,
                        color = self.lighten_color(
                            dataset,
                            2.0 - ((_q - 50) / 50)
                        ),
                        marker = self.__marker,
                        markersize = self.__markersize
                    )

        if self.__show_bar:
            matplotlib.pyplot.errorbar(
                [variate],
                [log.mean],
                yerr = [[log.mean - log.min], [log.max - log.mean]],
                figure = self.__figure,
                color = self.__colors[dataset],
                capsize = 0
            )

        if self.__show_min:
            if self.__show_bar:
                _, caplines, _ = matplotlib.pyplot.errorbar(
                    [variate],
                    [log.mean],
                    yerr = [log.mean - log.min],
                    figure = self.__figure,
                    color = self.__colors[dataset],
                    capsize = 0,
                    uplims = True
                )

                caplines[0].set_marker(self.__marker)
                caplines[0].set_markersize(self.__markersize)
            else:
                matplotlib.pyplot.plot(
                    variate,
                    log.min,
                    figure = self.__figure,
                    color = self.__colors[dataset],
                    marker = self.__marker,
                    markersize = self.__markersize
                )

        if self.__show_max:
            if self.__show_bar:
                _, caplines, _ = matplotlib.pyplot.errorbar(
                    [variate],
                    [log.mean],
                    yerr = [log.max - log.mean],
                    figure = self.__figure,
                    color = self.__colors[dataset],
                    capsize = 0,
                    lolims = True
                )

                caplines[0].set_marker(self.__marker)
                caplines[0].set_markersize(self.__markersize)
            else:
                matplotlib.pyplot.plot(
                    variate,
                    log.max,
                    figure = self.__figure,
                    color = self.__colors[dataset],
                    marker = self.__marker,
                    markersize = self.__markersize
                )


    def reduce_xticks(self):
        """Reduce the number of tick on the x axis.

        Call this before saving / showing the figure as it reduces
        the number of ticks on the x axis.

        Otherwise there is a tick for every x value.

        Source:
        https://stackoverflow.com/questions/6682784/reducing-number-of-plot-ticks
        """
        self.__axes.xaxis.set_major_locator(
            matplotlib.ticker.AutoLocator()
        )
        self.__axes.xaxis.set_minor_locator(
            matplotlib.ticker.AutoMinorLocator()
        )


    def set_ylim(self, ymin = None, ymax = None):
        """Set ymin and ymax in the figure."""
        self.__axes.set_ylim(ymin = ymin, ymax = ymax)


    def add_legend_handle(self, label, dataset = 0, marker = "o"):
        """Register a legend handle to be displayed inside the legend."""
        self.__legend_handles.append(
            matplotlib.pyplot.Line2D(
                [0], [0],
                label = label,
                color = "white",
                marker = marker,
                markerfacecolor = self.__colors[dataset % len(self.__colors)],
                markersize = 8,
            )
        )


    def show_legend(self, loc = None):
        """Show the legend in the figure with created handles."""
        self.__axes.legend(
            handles = self.__legend_handles,
            **{"loc": loc} if loc is not None else {}
        )


######################
# Log class
######################

class Log(object):
    """Object to store data from ng_trajectory log."""

    def __init__(
            self,
            filename: str = "",
            filestream: TextIO = None,
            show_quantiles: List[int] = [],
            merged_min: bool = False):
        """Initialize Log object."""
        super(Log, self).__init__()

        self.__filename = filename
        self.__parts = {}
        self.__others = []
        self.__failed = False
        self.__merged_min = merged_min

        if filename != "":
            with open(filename, "r") as f:
                self.load_data(f)
        else:
            self.__filename = filestream.name
            self.load_data(filestream)


        # And now for the preprocessing
        self.__penalty = [
            float(_p) for _p in self.__parts.get("penalty", [])
        ] + [float(_p) for _p in self.__parts.get("invalid", [])]
        self.__correct = [
            float(_c) for _c in self.__parts.get("correct", [])
        ]

        # Best solution is repeated once again at the end
        if len(self.__correct) > 0:
            self.__correct = self.__correct[:-1]
        else:
            self.__penalty = self.__penalty[:-1]
            self.__failed = True

        # Marker that some this have to be reevaluated
        self.__is_dirty = True

        # Quantiles to compute
        self.__show_quantiles = show_quantiles

        # And minimum stack
        self.__mins = [] if len(self.__correct) == 0 else [min(self.__correct)]

        # Track number of logs this is composed of
        self.__logs = 1


    def load_data(self, f: TextIO):
        """Load the data from a file."""
        # Hasten the process when '--merged-min' is used.
        # Note: This potentially breaks some options, but they were not used?
        if self.__merged_min:
            self.__parts["correct"] = [
                line.split(":")[1] for line in f if line.startswith("correct:")
            ]
            return

        for _li, line in enumerate(f):

            # Configuration
            if _li == 0:
                if line[0] == "{":
                    self.__configuration = line

            # Important parts
            if ":" in line:
                part = line.split(":")[0]

                if part not in self.__parts:
                    self.__parts[part] = []

                self.__parts[part].append(line[(line.index(":") + 1):-1])

            # The rest
            else:
                self.__others.append(line)


    def add(self, other):
        """Merge two logs by adding data from the other to self."""
        self.__correct += other.__correct
        self.__penalty += other.__penalty

        if len(other.__correct) == 0:
            self.__failed = True
        else:
            self.__mins.append(other.min)

        self.__is_dirty = True

        self.__logs += 1


    # # Statistics # #
    def recompute_statistics(self):  # noqa: E301
        """Recompute internal statistics of the Log."""
        self.__quantiles = quantiles(self.observed_list, n = 100)
        self.__is_dirty = False

    @property
    def observed_list(self):
        """Return data from the observed list.

        This resolves the fact that we are interested in slightly different
        data when using --merged-min.
        """
        return self.__correct if not self.__merged_min else self.__mins

    @property
    def min(self):
        """Obtain minimum of the currently observed list."""
        if len(self.observed_list) == 0:
            return None

        return min(self.observed_list)

    @property
    def max(self):
        """Obtain maximum of the currently observed list."""
        if len(self.observed_list) == 0:
            return None

        return max(self.observed_list)

    @property
    def mean(self):
        """Obtain mean of the currently observed list."""
        if len(self.observed_list) == 0:
            return None

        return statistics.mean(self.observed_list)

    @property
    def std(self):
        """Obtain std. dev. of the currently observed list."""
        if len(self.observed_list) <= 1:
            return None

        return statistics.stdev(self.observed_list)

    @property
    def rate(self):
        """Obtain success rate of the currently observed list."""
        if self.length == 0:
            return None

        return (self.successful_length) / (self.length)

    @property
    def successful_length(self):
        """Obtain number of the successful experiments in the observed list."""
        return (
            len(self.__correct) if not self.__merged_min
            else len(self.__mins)
        )

    @property
    def length(self):
        """Obtain number of values in the currently observed list."""
        return (
            len(self.__correct) + len(self.__penalty) if not self.__merged_min
            else self.__logs
        )

    @property
    def failed(self):
        """Return whether the experiment from the log failed."""
        return self.__failed


    def quantile(self, q: int):
        """Count 'q'-quantile."""
        if self.__is_dirty:
            self.recompute_statistics()

        return self.__quantiles[(q - 1) % 100]

    @property
    def quantile05(self):
        """Obtain 5-quantile."""
        return self.quantile(5)

    @property
    def quantile10(self):
        """Obtain 1-decile."""
        return self.quantile(10)

    @property
    def quantile90(self):
        """Obtain 9-decile."""
        return self.quantile(90)

    @property
    def quantile95(self):
        """Obtain 95-quantile."""
        return self.quantile(95)

    @property
    def quantile_show_list(self):
        """Obtain all requested quantiles."""
        return self.__show_quantiles


    def __str__(self):
        """Convert the log into a string."""
        s = ""

        # Filename
        s += "Log: %s\n" % self.__filename

        # Others
        s += "Others: %s\n" % "\n".join(self.__others)

        # Success rate
        s += "Success rate: %f%% (%d out of %d)\n" % (
            100.0 * self.rate,
            self.successful_length,
            self.length
        )

        # Statistics
        if self.successful_length > 0:
            s += "Solution statistics:\n\t"
            s += "Min: %f\n\t" % self.min

            Q = "\n\t".join(
                [
                    "Q%02d: %f" % (_q, self.quantile(_q))
                    for _q in self.__show_quantiles if _q < 50
                ]
            )
            if Q != "":
                s += Q + "\n\t"

            s += "Avg: %f\n\t" % self.mean

            Q = "\n\t".join(
                [
                    "Q%02d: %f" % (_q, self.quantile(_q))
                    for _q in self.__show_quantiles if _q > 50
                ]
            )
            if Q != "":
                s += Q + "\n\t"

            s += "\n\t".join([
                "Max: %f" % self.max,
                "Std: %f" % self.std,
            ]) + "\n"


        return (s)


######################
# Utilities
######################

def quantiles(data, n = 10, method = "inclusive"):
    """Ported from Python 3.10.

    https://github.com/python/cpython/blob/3.10/Lib/statistics.py

    Note: We are using 'inclusive' as default (similar to numpy),
    as it is what we want.

    Inclusive observes the data as min-max, exclusive expects that
    the extrema might be outside of the given data.
    """
    if n < 1:
        raise ValueError("n must be at least 1")
    data = sorted(data)
    ld = len(data)
    if ld < 2:
        raise ValueError("must have at least two data points")
    if method == "inclusive":
        m = ld - 1
        result = []
        for i in range(1, n):
            j, delta = divmod(i * m, n)
            interpolated = (data[j] * (n - delta) + data[j + 1] * delta) / n
            result.append(interpolated)
        return result
    if method == "exclusive":
        m = ld + 1
        result = []
        for i in range(1, n):
            j = i * m // n                               # rescale i to m/n
            j = (
                1 if j < 1 else ld - 1 if j > ld - 1 else j
            )                                            # clamp to 1 .. ld-1
            delta = i * m - j * n                        # exact integer math
            interpolated = (data[j - 1] * (n - delta) + data[j] * delta) / n
            result.append(interpolated)
        return result
    raise ValueError("Unknown method: %s" % str(method))


def scale_lightness(rgb: Tuple[float], scale_l: float):
    """Scale the lightness of a color.

    Source:
    https://stackoverflow.com/questions/37765197/darken-or-lighten-a-color-in-matplotlib
    """
    # convert rgb to hls
    h, l, s = colorsys.rgb_to_hls(*rgb)
    # manipulate h, l, s values and return as rgb
    return colorsys.hls_to_rgb(h, min(1, l * scale_l), s = s)


######################
# Log files
######################

def _process_log(
        log_set: Tuple[int, str]):
    """Process a log. Used to support parallel computing.

    Arguments:
    log_set -- tuple of value and filename

    Returns:
    value, log
    """
    global args

    return (
        log_set[0],
        Log(
            filename = log_set[1],
            show_quantiles = args.quantiles,
            merged_min = args.merged_min
        )
    )


def _process_logs(
        log_set: Tuple[str, Dict[str, Dict[str, str]]]) \
        -> Tuple[str, Dict[str, object]]:
    """Process a dict of log names.

    Arguments:
    log_set -- tuple of variate and dict of log_names

    Returns:
    variate, logs
    """
    global args

    variate = log_set[0]
    log_names = log_set[1]

    logs = {}

    for _li, loop in enumerate(log_names):
        for _i, step in enumerate(log_names[loop]):

            _logname = os.path.join(
                os.path.dirname(input_file),
                log_names[loop][step]
            )
            if not args.recursive_find:
                if not os.path.exists(_logname):
                    continue
            else:
                for dirpath, _, filenames in os.walk("."):
                    if _logname in filenames:
                        _logname = os.path.join(dirpath, _logname)
                        break
                else:
                    continue

            if _i not in logs:
                logs[_i] = Log(
                    _logname,
                    show_quantiles = args.quantiles,
                    merged_min = args.merged_min
                )
            else:
                _log = Log(
                    _logname,
                    show_quantiles = args.quantiles,
                    merged_min = args.merged_min
                )
                logs[_i].add(_log)

    return variate, logs


"""
Conditional parallelization.
Decorated function is run as sequential, for parallel execution
we run the function passed to the decorator.
"""
@parallel(_process_log)  # noqa: E302
def process_log(*args, **kwargs):  # noqa: D103
    pass


@parallel(_process_logs)
def process_logs(*args, **kwargs):  # noqa: D103
    pass


def construct_log_names(
        configuration: Dict[str, any]) -> Dict[str, any]:
    """Construct all names of the logs according to the configuration.

    The dictionary is created as:
    - variate (if applicable)
      - loops
        - cascade steps
          - name of the log

    Note: Yes, it is quite ugly, but this is currently the best (and simplest?)
          way to do it.
    """
    # # a) Check for prefix # #
    if "prefix" not in configuration:
        print (
            "Selected configuration does not create logs. "
            "Add 'prefix' parameter to create them.",
            file = sys.stderr
        )
        exit (4)

    _prefix = configuration.get("prefix")

    # # b) Check for variate # #
    _variate = (
        configuration.get(configuration.get("variate"))
        if "variate" in configuration else []
    )

    # # c) Get loops # #
    _loops = configuration.get("loops")

    # # d) Get cascade # #
    _cascade = configuration.get("cascade")


    lognames = {}
    filename = "%s" % _prefix

    if _variate == []:
        lognames[""] = construct_log_names_variate(
            filename,
            _loops,
            _cascade,
            configuration.get("algorithm", "")
        )
    else:
        if all([isinstance(_value, int) for _value in _variate]):
            variate_suffix = "%%0%dd" % len(str(max(_variate)))
        else:
            variate_suffix = "%s"

        for value in _variate:
            lognames[variate_suffix % value] = construct_log_names_variate(
                filename + "-" + variate_suffix % value,
                _loops,
                _cascade,
                (
                    value if configuration.get("variate") == "algorithm"
                    else configuration.get("algorithm", "")
                )
            )

    return lognames


def construct_log_names_variate(
        filename: str,
        loops: int,
        cascade: List[Dict[str, any]],
        algorithm: str = "") -> Dict[str, any]:
    """Construct the log names according to the variate parameter."""
    lognames = {}

    loops_suffix = "%%0%dd" % len(str(loops))

    for loop in range(loops):
        current_loop = loops_suffix % (loop + 1)

        lognames[current_loop] = {}

        cascade_suffix = "%%0%dd" % len(str(len(cascade)))

        for _i, step in enumerate(cascade):
            current_step = cascade_suffix % (_i + 1)

            lognames[current_loop][current_step] = (
                filename + "-" + current_loop + "-" + current_step
                + "-%s.log" % step.get("algorithm", algorithm)
            )

    return lognames


def construct_log_names_legacy(
        configuration: Dict[str, any]) -> Dict[str, any]:
    """Construct all names of the logs according to the legacy configuration.

    The dictionary is created as:
    - groups_list
      - loops
        - cascade steps
          - name of the log

    Note: Yes, this is even worse. But I have some
          old logs that could be processed.
    """
    # # a) Check for prefix # #
    if "prefix" not in configuration:
        print (
            "Selected configuration does not create logs. "
            "Add 'prefix' parameter to create them.",
            file = sys.stderr
        )
        exit (4)

    _prefix = configuration.get("prefix")

    # # b) Check for variate # #
    _variate = configuration.get("groups_list", [configuration.get("groups")])

    # # c) Get loops # #
    _loops = configuration.get("loops")

    # # d) Get cascade # #
    # _cascade = configuration.get("cascade")


    lognames = {}
    filename = "%s" % _prefix

    variate_suffix = "%03d"

    for value in _variate:
        current_variate = variate_suffix % value
        lognames[current_variate] = {}

        loops_suffix = "%03d"

        for loop in range(_loops):
            current_loop = loops_suffix % (loop + 1)

            lognames[current_variate][current_loop] = {}

            current_step = "1"

            lognames[current_variate][current_loop][current_step] = (
                filename + current_variate + "-" + current_loop + ".log"
            )

    return lognames


######################
# Figures
######################

def save_figure():
    """Save current figure."""
    global args

    if not args.outfile:
        outfile = args.input_file[0].name

        if outfile.endswith(".json"):
            outfile = outfile[:-5]

        if len(args.input_file) > 1:
            outfile += "-multiple%d" % len(args.input_file)
    else:
        outfile = args.outfile

    matplotlib.pyplot.savefig(outfile + ".pdf", format = "pdf", dpi = args.dpi)
    matplotlib.pyplot.savefig(outfile + ".png", format = "png", dpi = args.dpi)


######################
# Main
######################

if __name__ == "__main__":

    # Obtain arguments
    args = PARSER.parse_args()

    if not args.logfile:
        g = Graph(
            xlabel = "num. of segments [-]",
            ylabel = "lap time [s]",
            show_min = args.show_min,
            show_max = args.show_max,
            show_avg = args.show_avg,
            show_bar = args.show_bar,
            marker = args.marker,
            markersize = args.markersize,
            width = args.width,
            height = args.height
        )

        for _if, input_file in enumerate(
            tqdm.tqdm(args.input_file, desc = "JSON")
        ):
            # Load configuration
            with open(input_file, "r") as f:
                configuration = json.loads(f.read())

            # Store label
            _label = (
                args.label[_if]
                if args.label is not None and len(args.label) > _if
                else configuration.get("_label", os.path.basename(input_file))
            )

            # Construct names of all expected files
            if configuration.get("_version", None) > 1:
                log_names = construct_log_names(configuration)
            else:
                log_names = construct_log_names_legacy(configuration)

            # Change the dataset value if requested
            # (changes the data appearance)
            if len(args.datasets) > 0:
                _if = args.datasets.get(_if)

            # Process the logs
            for x, logs in tqdm.tqdm(
                process_logs(log_names.items()),
                desc = "Logs",
                leave = False,
                total = len(log_names.keys()),
            ):

                if args.step in logs:

                    try:
                        x = float(x)

                        if len(args.variates) > 0:
                            if x not in args.variates:
                                continue
                    except ValueError:
                        pass

                    g.plot_log(
                        logs[args.step],
                        variate = x,
                        dataset = _if,
                        marker = args.marker_avg.get(_if)
                    )

            if args.show_legend:
                g.add_legend_handle(
                    label = _label,
                    dataset = _if,
                    marker = args.marker_avg.get(_if),
                )

        if args.show_legend:
            g.show_legend(loc = args.loc_legend)

        if args.title != "":
            matplotlib.pyplot.title(args.title)

        g.reduce_xticks()
        g.set_ylim(ymin = args.ymin, ymax = args.ymax)

        if args.tight:
            matplotlib.pyplot.tight_layout()

        if not args.save:
            matplotlib.pyplot.show()
        else:
            save_figure()

    else:
        if args.show_graph:
            g = Graph(
                xlabel = "num. of segments [-]",
                ylabel = "lap time [s]",
                show_min = args.show_min,
                show_max = args.show_max,
                show_avg = args.show_avg,
                show_bar = args.show_bar,
                marker = args.marker,
                markersize = args.markersize,
                width = args.width,
                height = args.height
            )

            _log = None

            # Process the logs
            for _n, l in tqdm.tqdm(
                process_log(enumerate(args.input_file)),
                desc = "Logs",
                total = len(args.input_file),
            ):
                if args.merged_min:
                    if _n == 0:
                        _log = l
                        continue

                    _log.add(l)

                    if _n == len(args.input_file) - 1:
                        l = _log  # noqa: E741
                    else:
                        continue

                g.plot_log(
                    l,
                    variate = _n if len(args.segments) == 0 else (
                        args.segments.get(_n)
                    ),
                    marker = args.marker_avg.get(_if),
                )

            if args.title != "":
                matplotlib.pyplot.title(args.title)

            g.reduce_xticks()
            g.set_ylim(ymin = args.ymin, ymax = args.ymax)

            if args.tight:
                matplotlib.pyplot.tight_layout()

            if not args.save:
                matplotlib.pyplot.show()
            else:
                save_figure()

        else:
            _header_shown = args.no_header

            _log = None

            for _n, l in process_log(enumerate(args.input_file)):
                if args.merged_min:
                    if _n == 0:
                        _log = l
                        continue

                    _log.add(l)

                    if _n == len(args.input_file) - 1:
                        l = _log  # noqa: E741
                    else:
                        continue

                if not args.plot_friendly:
                    print(l)
                else:
                    if not _header_shown:
                        print (
                            ",".join(
                                (["seg"] if len(args.segments) > 0 else [])
                                + ["len,rate,min,avg,max,std"]
                                + ["Q%02d" % _q for _q in l.quantile_show_list]
                            )
                        )
                        _header_shown = True

                    print (
                        ",".join([
                            "%s" % s for s in (
                                [args.segments.get(_n)]
                                if len(args.segments) > 0 else []
                            )
                            + [l.length, l.rate, l.min, l.mean, l.max, l.std]
                            + [l.quantile(_q) for _q in l.quantile_show_list]
                        ])
                    )
